{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jenv-YgSElT1"
   },
   "source": [
    "# Task 1: Small case scenario of dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZ6YahZgAZvB"
   },
   "source": [
    "## 1.1 - Create a dataset (The Tate Collection)\n",
    "As a first example, we will create our own small dataset. In particular, the dataset will consist of 10 artists which are present in the Tate Collection along with the corresponding year of birth, year of death, biological gender and number of artworks.\n",
    "\n",
    "|          Name         | Gender |   Year_Birth  |   Year_Death  | N_works |\n",
    "|-----------------------|--------|---------------|---------------|---------|\n",
    "|     Beuys, Joseph     |  Male  |      1921\t |      1986     |   588   |\n",
    "|    Constable, John    |  Male  |      1776\t |      1837\t |   249   |\n",
    "|   Daniell, William    |  Male  |      1769\t |      1837\t |   612   |\n",
    "|   Forbes, Elizabeth   | Female |      1859\t |      1912\t |   120   |\n",
    "|     Flaxman, John     |  Male  |      1755\t |      1826\t |   287   |\n",
    "|    Phillips, Thomas   |  Male  |      1770\t |      1845\t |   274   |\n",
    "| Paolozzi, Sir Eduardo |  Male  |      1924\t |      2005\t |   385   |\n",
    "|     Schendel, Mira    | Female |      1919\t |      1988\t |    3    |\n",
    "|    Turner, William    |  Male  |      1775\t |      1851\t |  1861   |\n",
    "|      Warhol, Andy     |  Male  |      1928\t |      1987\t |   272   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV1sgIOzAZvD"
   },
   "source": [
    "**_[TO DO]_**: Let's create a DataFrame named **TateDataset** with the information showed in the above table.\n",
    "\n",
    "**Note:** You can create arrays for each column and then build the DataFrame.\n",
    "Remember to import the required libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1603899361329,
     "user": {
      "displayName": "Sephora Madjiheurem",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgieP2Hh5x42748iuuSEnAl8BYCWGSmOzJ-ypgSaQ=s64",
      "userId": "05055971560005673839"
     },
     "user_tz": 0
    },
    "id": "NxkzhjIGAZvF"
   },
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FWsJFvTQB3hX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name  Gender  Year_Birth  Year_Death  N_works\n",
      "0          Beuys, Joseph    Male        1921        1986      588\n",
      "1        Constable, John    Male        1776        1837      249\n",
      "2       Daniell, William    Male        1769        1837      612\n",
      "3      Forbes, Elizabeth  Female        1859        1912      120\n",
      "4          Flaxman, John    Male        1755        1826      287\n",
      "5       Phillips, Thomas    Male        1770        1845      274\n",
      "6  Paolozzi, Sir Eduardo    Male        1924        2005      385\n",
      "7         Schendel, Mira  Female        1919        1988        3\n",
      "8        Turner, William    Male        1775        1851     1861\n",
      "9           Warhol, Andy    Male        1928        1987      272\n"
     ]
    }
   ],
   "source": [
    "### TODO\n",
    "name = ['Beuys, Joseph', 'Constable, John', 'Daniell, William', 'Forbes, Elizabeth', 'Flaxman, John', 'Phillips, Thomas','Paolozzi, Sir Eduardo', 'Schendel, Mira', 'Turner, William', 'Warhol, Andy']\n",
    "\n",
    "gender = ['Male', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male']\n",
    "year_birth = np.array([1921, 1776, 1769, 1859, 1755, 1770, 1924, 1919, 1775, 1928], dtype=np.int64)\n",
    "year_death = np.array([1986, 1837, 1837, 1912, 1826, 1845, 2005, 1988, 1851, 1987], dtype=np.int64)\n",
    "n_works = np.array([588, 249, 612, 120, 287, 274, 385, 3, 1861, 272], dtype=np.int64)\n",
    "\n",
    "columns = ['Name', 'Gender', 'Year_Birth', 'Year_Death', 'N_works']\n",
    "\n",
    "tate_dataset = pd.DataFrame(data = {'Name': name, 'Gender': gender, 'Year_Birth': year_birth, 'Year_Death': year_death, 'N_works': n_works})\n",
    "print(tate_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0P3DpT-VAZvO"
   },
   "source": [
    "## 1.2 - Data Acquisition (local file)\n",
    "\n",
    "Data acquisition is a process of loading and reading data from various sources. We will learn how to export and read data from a local file in different format using  **Pandas** package. \n",
    "\n",
    "A file format is a standardised way in which information is encoded to be stored in a file. Some examples of file formats are: CSV, XLSX, and PKL. \n",
    "\n",
    "Let's practice with some examples.\n",
    "\n",
    "###Â .CSV - Comma Separated Values\n",
    "\n",
    "CSV is one of the most popular spreadsheet file format. In this kind of file, data is stored in cells. Each cell is organized in rows and columns. A column in the spreadsheet file can have different types. \n",
    "\n",
    "Let us look at how to create a CSV file. We can export a DataFrame with the Pandas function `to_csv()`. The file will be saved in the same location of this notebook unless specified otherwise. We can name the file **TateData.csv**.\n",
    "\n",
    "**Note:** Once you have run the following cell, check the output file ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DcFThhwRAZvP"
   },
   "outputs": [],
   "source": [
    "tate_dataset.to_csv('tate_dataset.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54BZQJs8AZvU"
   },
   "source": [
    "To pull in the csv file, we will use the Pandas function `read_csv()`. We will import the previous file in a new DataFrame.\n",
    "\n",
    "**Note:**  Depending on where you save your notebooks, you may need to modify the location below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PcO3epU5AZvV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Year_Death</th>\n",
       "      <th>N_works</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beuys, Joseph</td>\n",
       "      <td>Male</td>\n",
       "      <td>1921</td>\n",
       "      <td>1986</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Constable, John</td>\n",
       "      <td>Male</td>\n",
       "      <td>1776</td>\n",
       "      <td>1837</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniell, William</td>\n",
       "      <td>Male</td>\n",
       "      <td>1769</td>\n",
       "      <td>1837</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forbes, Elizabeth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1859</td>\n",
       "      <td>1912</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flaxman, John</td>\n",
       "      <td>Male</td>\n",
       "      <td>1755</td>\n",
       "      <td>1826</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phillips, Thomas</td>\n",
       "      <td>Male</td>\n",
       "      <td>1770</td>\n",
       "      <td>1845</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paolozzi, Sir Eduardo</td>\n",
       "      <td>Male</td>\n",
       "      <td>1924</td>\n",
       "      <td>2005</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schendel, Mira</td>\n",
       "      <td>Female</td>\n",
       "      <td>1919</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turner, William</td>\n",
       "      <td>Male</td>\n",
       "      <td>1775</td>\n",
       "      <td>1851</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warhol, Andy</td>\n",
       "      <td>Male</td>\n",
       "      <td>1928</td>\n",
       "      <td>1987</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Gender  Year_Birth  Year_Death  N_works\n",
       "0          Beuys, Joseph    Male        1921        1986      588\n",
       "1        Constable, John    Male        1776        1837      249\n",
       "2       Daniell, William    Male        1769        1837      612\n",
       "3      Forbes, Elizabeth  Female        1859        1912      120\n",
       "4          Flaxman, John    Male        1755        1826      287\n",
       "5       Phillips, Thomas    Male        1770        1845      274\n",
       "6  Paolozzi, Sir Eduardo    Male        1924        2005      385\n",
       "7         Schendel, Mira  Female        1919        1988        3\n",
       "8        Turner, William    Male        1775        1851     1861\n",
       "9           Warhol, Andy    Male        1928        1987      272"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tate_1 = pd.read_csv('tate_dataset.csv')\n",
    "tate_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CmXNd9jAZva"
   },
   "source": [
    "When we create the .CSV file, the only parameter we have used is **index**. \n",
    "\n",
    "**[TO DO]** What happens if we set the *index* parameter to True? And if you set also the parameter **header** to False?\n",
    "Try by yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "egR7HZLaAZvb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Beuys, Joseph</th>\n",
       "      <th>Male</th>\n",
       "      <th>1921</th>\n",
       "      <th>1986</th>\n",
       "      <th>588</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Constable, John</td>\n",
       "      <td>Male</td>\n",
       "      <td>1776</td>\n",
       "      <td>1837</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Daniell, William</td>\n",
       "      <td>Male</td>\n",
       "      <td>1769</td>\n",
       "      <td>1837</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Forbes, Elizabeth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1859</td>\n",
       "      <td>1912</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Flaxman, John</td>\n",
       "      <td>Male</td>\n",
       "      <td>1755</td>\n",
       "      <td>1826</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phillips, Thomas</td>\n",
       "      <td>Male</td>\n",
       "      <td>1770</td>\n",
       "      <td>1845</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Paolozzi, Sir Eduardo</td>\n",
       "      <td>Male</td>\n",
       "      <td>1924</td>\n",
       "      <td>2005</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Schendel, Mira</td>\n",
       "      <td>Female</td>\n",
       "      <td>1919</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Turner, William</td>\n",
       "      <td>Male</td>\n",
       "      <td>1775</td>\n",
       "      <td>1851</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Warhol, Andy</td>\n",
       "      <td>Male</td>\n",
       "      <td>1928</td>\n",
       "      <td>1987</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          Beuys, Joseph    Male  1921  1986   588\n",
       "0  1        Constable, John    Male  1776  1837   249\n",
       "1  2       Daniell, William    Male  1769  1837   612\n",
       "2  3      Forbes, Elizabeth  Female  1859  1912   120\n",
       "3  4          Flaxman, John    Male  1755  1826   287\n",
       "4  5       Phillips, Thomas    Male  1770  1845   274\n",
       "5  6  Paolozzi, Sir Eduardo    Male  1924  2005   385\n",
       "6  7         Schendel, Mira  Female  1919  1988     3\n",
       "7  8        Turner, William    Male  1775  1851  1861\n",
       "8  9           Warhol, Andy    Male  1928  1987   272"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO\n",
    "tate_dataset.to_csv('tate_dataset.csv', index=True, header=False)\n",
    "tate_1 = pd.read_csv('tate_dataset.csv')\n",
    "tate_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Solution\n",
    "index = true returns row names, and header = false drops the header labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tHt7lPFAZvf"
   },
   "source": [
    "Delete the csv file now that we are done using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQLf1Y_hAZvr"
   },
   "source": [
    "### pickle â Python object serialization\n",
    "\n",
    "This data format is Python-specific. This has the advantage that there are no restrictions imposed by external standards; however it means that non-Python programs may not be able to reconstruct pickled Python objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "stKRPdBTAZvr"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tate_dataset.to_pickle('tate_dataset.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Rc7RsQeKAZvt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Year_Death</th>\n",
       "      <th>N_works</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beuys, Joseph</td>\n",
       "      <td>Male</td>\n",
       "      <td>1921</td>\n",
       "      <td>1986</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Constable, John</td>\n",
       "      <td>Male</td>\n",
       "      <td>1776</td>\n",
       "      <td>1837</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniell, William</td>\n",
       "      <td>Male</td>\n",
       "      <td>1769</td>\n",
       "      <td>1837</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forbes, Elizabeth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1859</td>\n",
       "      <td>1912</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flaxman, John</td>\n",
       "      <td>Male</td>\n",
       "      <td>1755</td>\n",
       "      <td>1826</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phillips, Thomas</td>\n",
       "      <td>Male</td>\n",
       "      <td>1770</td>\n",
       "      <td>1845</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paolozzi, Sir Eduardo</td>\n",
       "      <td>Male</td>\n",
       "      <td>1924</td>\n",
       "      <td>2005</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schendel, Mira</td>\n",
       "      <td>Female</td>\n",
       "      <td>1919</td>\n",
       "      <td>1988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turner, William</td>\n",
       "      <td>Male</td>\n",
       "      <td>1775</td>\n",
       "      <td>1851</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warhol, Andy</td>\n",
       "      <td>Male</td>\n",
       "      <td>1928</td>\n",
       "      <td>1987</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Gender  Year_Birth  Year_Death  N_works\n",
       "0          Beuys, Joseph    Male        1921        1986      588\n",
       "1        Constable, John    Male        1776        1837      249\n",
       "2       Daniell, William    Male        1769        1837      612\n",
       "3      Forbes, Elizabeth  Female        1859        1912      120\n",
       "4          Flaxman, John    Male        1755        1826      287\n",
       "5       Phillips, Thomas    Male        1770        1845      274\n",
       "6  Paolozzi, Sir Eduardo    Male        1924        2005      385\n",
       "7         Schendel, Mira  Female        1919        1988        3\n",
       "8        Turner, William    Male        1775        1851     1861\n",
       "9           Warhol, Andy    Male        1928        1987      272"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tate_2 = pd.read_pickle('tate_dataset.pkl')\n",
    "tate_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vHSnaOQAZvv"
   },
   "source": [
    "## 1.3 - Look at the data\n",
    "\n",
    "Now we will simply have a look at the data and make sure it is clean. \n",
    "\n",
    "### Data type\n",
    "Let's check the data type of the imported variables and the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AV3eoT35AZvw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 int64\n",
       "Beuys, Joseph    object\n",
       "Male             object\n",
       "1921              int64\n",
       "1986              int64\n",
       "588               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data type of the columns for Tate_1\n",
    "tate_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ACysmIDSAZvy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          object\n",
       "Gender        object\n",
       "Year_Birth     int64\n",
       "Year_Death     int64\n",
       "N_works        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data type of the columns for TateDataset\n",
    "tate_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3q0dEk0AZv0"
   },
   "source": [
    "We can also display the values of a single column and check their data type as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zfMt0x2lAZv0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Male\n",
       "1      Male\n",
       "2      Male\n",
       "3    Female\n",
       "4      Male\n",
       "5      Male\n",
       "6      Male\n",
       "7    Female\n",
       "8      Male\n",
       "9      Male\n",
       "Name: Gender, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tate_dataset['Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hympM9yTEuud"
   },
   "source": [
    "# Task 2: Application Programming Interfaces (APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOGrvILtFv0K",
    "tags": []
   },
   "source": [
    "## 2.1 - Downloading climate data from the Internet\n",
    "\n",
    "We will now explore real world data, namely a dataset of climate information of 5 cities in Denmark between 1980-2018. The original raw-data was originally obtained from [National Climatic Data Center (NCDC)](https://www7.ncdc.noaa.gov/CDO/cdoselect.cmd).\n",
    "\n",
    "In particular, the selected cities in Denmark are:\n",
    "- Aalborg, \n",
    "- Aarhus, \n",
    "- Esbjerg, \n",
    "- Odense. \n",
    "- Roskilde\n",
    "\n",
    "In the following, we will download the dataset using an API instead of loading a local source file.\n",
    "\n",
    "### What is an API? \n",
    "Application Programming Interface (API) is a communication protocol between the user and the server (i.e., web server) that enables transmittion of data. The user making a request to an API server can download the desidered resources. \n",
    "\n",
    "### How to make a request in python?\n",
    "There are many different way to request data. \n",
    "In the following, we will use the package **urllib** that collects several modules for working with URLs.\n",
    "\n",
    "In particular, [urlib.request](https://docs.python.org/3/library/urllib.request.html#module-urllib.request) is a module for opening and reading URLs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiwhudMrKQUP"
   },
   "source": [
    "### - Download climate data\n",
    "\n",
    "\n",
    "The following functions allow to download and store the dataset in a specific folder.\n",
    "\n",
    "How to use:\n",
    "\n",
    "- Set the source (i.e., URL) of the desidered dataset in `data_url`.\n",
    "- Set the `data_dir` variable with the local directory where to store the data.\n",
    "- Call `download_and_extract()` to download the dataset if it is not already located in the given data_dir.\n",
    "- Load the data in the interactive Python notebook so ic can be used in your scripts (you can use `load_original_data()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "id": "DjVqxHOLE6I4"
   },
   "outputs": [],
   "source": [
    "#@title Functions to download data \n",
    "########################################################################\n",
    "#\n",
    "# This file is a partially modified version of one of the TensorFlow Tutorials available at:\n",
    "#\n",
    "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "#\n",
    "# Published under the MIT License. See the file LICENSE for details.\n",
    "#\n",
    "# Copyright 2018 by Magnus Erik Hvass Pedersen\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "def _print_download_progress(count, block_size, total_size):\n",
    "    \"\"\"\n",
    "    Function used for printing the download progress.\n",
    "    Used as a call-back function in maybe_download_and_extract().\n",
    "    \"\"\"\n",
    "\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "\n",
    "    # Limit it because rounding errors may cause it to exceed 100%.\n",
    "    pct_complete = min(1.0, pct_complete)\n",
    "\n",
    "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def download(base_url, filename, download_dir):\n",
    "    \"\"\"\n",
    "    Download the given file if it does not already exist in the download_dir.\n",
    "    :param base_url: The internet URL without the filename.\n",
    "    :param filename: The filename that will be added to the base_url.\n",
    "    :param download_dir: Local directory for storing the file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Path for local file.\n",
    "    save_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Check if the file already exists, otherwise we need to download it now.\n",
    "    if not os.path.exists(save_path):\n",
    "        # Check if the download directory exists, otherwise create it.\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "\n",
    "        print(\"Downloading\", filename, \"...\")\n",
    "\n",
    "        # Download the file from the internet.\n",
    "        url = base_url + filename\n",
    "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
    "                                                  filename=save_path,\n",
    "                                                  reporthook=_print_download_progress)\n",
    "\n",
    "        print(\" Done!\")\n",
    "\n",
    "\n",
    "def download_and_extract(url, download_dir):\n",
    "    \"\"\"\n",
    "    Download and extract the data if it doesn't already exist.\n",
    "    Assumes the url is a tar-ball file.\n",
    "    :param url:\n",
    "        Internet URL for the tar-file to download.\n",
    "    :param download_dir:\n",
    "        Directory where the downloaded file is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filename for saving the file downloaded from the internet.\n",
    "    # Use the filename from the URL and add it to the download_dir.\n",
    "    filename = url.split('/')[-1]\n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Check if the file already exists.\n",
    "    # If it exists then we assume it has also been extracted,\n",
    "    # otherwise we need to download and extract it now.\n",
    "    if not os.path.exists(file_path):\n",
    "        # Check if the download directory exists, otherwise create it.\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "\n",
    "        # Download the file from the internet.\n",
    "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
    "                                                  filename=file_path,\n",
    "                                                  reporthook=_print_download_progress)\n",
    "\n",
    "        print()\n",
    "        print(\"Download finished. Extracting files.\")\n",
    "\n",
    "        if file_path.endswith(\".zip\"):\n",
    "            # Unpack the zip-file.\n",
    "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
    "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
    "            # Unpack the tar-ball.\n",
    "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
    "\n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhAOVRKTclRR"
   },
   "source": [
    "First, we define where we want to download the dataset (you are free to choose another directory) and the URL of the dataset to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mPl5lGC_cjRa"
   },
   "outputs": [],
   "source": [
    "# Location of the dataset on the internet.\n",
    "data_url = \"https://github.com/Hvass-Labs/weather-denmark/raw/master/weather-denmark.tar.gz\"\n",
    "\n",
    "# Local directory where you want to download and save the dataset.\n",
    "data_dir = \"weather-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fUv_1U7AGIS"
   },
   "source": [
    "Now, we can download the dataset into the chosen local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6P4iL6WfAGIT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "download_and_extract(url=data_url, download_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLC9mO_RAGIY"
   },
   "source": [
    "**[TO DO]:** Check the local folder? In which format the dataset has been downloaded?\n",
    "\n",
    "**[TO DO]:** Select a format and load the dataset ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Dataset has been downloaded in csv and pkl, here we can use either format in loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "59A_u_4CAGIY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>1980-03-01 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1008.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>1980-03-01 00:20:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>1980-03-01 00:50:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>1980-03-01 01:20:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>1980-03-01 01:50:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918145</th>\n",
       "      <td>Roskilde</td>\n",
       "      <td>2018-03-01 22:20:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918146</th>\n",
       "      <td>Roskilde</td>\n",
       "      <td>2018-03-01 22:50:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918147</th>\n",
       "      <td>Roskilde</td>\n",
       "      <td>2018-03-01 23:00:00</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1018.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918148</th>\n",
       "      <td>Roskilde</td>\n",
       "      <td>2018-03-01 23:20:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918149</th>\n",
       "      <td>Roskilde</td>\n",
       "      <td>2018-03-01 23:50:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2918150 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             City             DateTime  Temp  Pressure  WindSpeed  WindDir\n",
       "0         Aalborg  1980-03-01 00:00:00   5.0    1008.1       11.3    290.0\n",
       "1         Aalborg  1980-03-01 00:20:00   4.0       NaN        9.2    270.0\n",
       "2         Aalborg  1980-03-01 00:50:00   4.0       NaN        9.2    280.0\n",
       "3         Aalborg  1980-03-01 01:20:00   4.0       NaN        9.2    280.0\n",
       "4         Aalborg  1980-03-01 01:50:00   4.0       NaN        8.7    270.0\n",
       "...           ...                  ...   ...       ...        ...      ...\n",
       "2918145  Roskilde  2018-03-01 22:20:00  -5.0       NaN        5.1     70.0\n",
       "2918146  Roskilde  2018-03-01 22:50:00  -5.0       NaN        4.1     70.0\n",
       "2918147  Roskilde  2018-03-01 23:00:00  -5.3    1018.6        4.1     60.0\n",
       "2918148  Roskilde  2018-03-01 23:20:00  -5.0       NaN        3.6     60.0\n",
       "2918149  Roskilde  2018-03-01 23:50:00  -5.0       NaN        3.6     60.0\n",
       "\n",
       "[2918150 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO\n",
    "df_csv = pd.read_csv('./weather-data/weather-denmark.csv')\n",
    "#df_pkl = pd.read_pickle('./weather-data/weather-denmark.pkl')\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "36clsIOhq_CR"
   },
   "outputs": [],
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN4_qGC4AGIc"
   },
   "source": [
    "**More advanced solution for loading dataset**:\n",
    "\n",
    "In this case, the dataset was downloaded in two different formats. \n",
    "We can define the path where the files have been stored as follows:\n",
    "- **path_original_data_pickle( )** is the location of the original data in pickle format\n",
    "- **path_original_data_csv( )** is the location the original data in .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NO8jevNRAGIc"
   },
   "outputs": [],
   "source": [
    "def path_original_data_pickle():\n",
    "    return os.path.join(data_dir, \"weather-denmark.pkl\")\n",
    "\n",
    "def path_original_data_csv():\n",
    "    return os.path.join(data_dir, \"weather-denmark.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoNQaCyAAGIg"
   },
   "source": [
    "Now we can load the data in pickle format through the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JHdwG7c6AGIh"
   },
   "outputs": [],
   "source": [
    "def load_original_data():\n",
    "    return pd.read_pickle(path_original_data_pickle())\n",
    "    #return pd.read_csv(path_original_data_csv()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0-XPffh3AGIj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Aalborg</th>\n",
       "      <th>1980-03-01 00:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1008.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 00:20:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 00:50:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 01:20:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 01:50:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Roskilde</th>\n",
       "      <th>2018-03-01 22:20:00</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 22:50:00</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 23:00:00</th>\n",
       "      <td>-5.3</td>\n",
       "      <td>1018.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 23:20:00</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 23:50:00</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2918150 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Temp  Pressure  WindSpeed  WindDir\n",
       "City     DateTime                                               \n",
       "Aalborg  1980-03-01 00:00:00   5.0    1008.1       11.3    290.0\n",
       "         1980-03-01 00:20:00   4.0       NaN        9.2    270.0\n",
       "         1980-03-01 00:50:00   4.0       NaN        9.2    280.0\n",
       "         1980-03-01 01:20:00   4.0       NaN        9.2    280.0\n",
       "         1980-03-01 01:50:00   4.0       NaN        8.7    270.0\n",
       "...                            ...       ...        ...      ...\n",
       "Roskilde 2018-03-01 22:20:00  -5.0       NaN        5.1     70.0\n",
       "         2018-03-01 22:50:00  -5.0       NaN        4.1     70.0\n",
       "         2018-03-01 23:00:00  -5.3    1018.6        4.1     60.0\n",
       "         2018-03-01 23:20:00  -5.0       NaN        3.6     60.0\n",
       "         2018-03-01 23:50:00  -5.0       NaN        3.6     60.0\n",
       "\n",
       "[2918150 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_original_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMCJQr_SAGIm"
   },
   "source": [
    "### - Undestanding the data\n",
    "\n",
    "**_[TO DO]_**: Have a quick overview of the downloaded dataset. \n",
    "In particular, focus on:\n",
    "\n",
    "- Understanding the variables contained in the dataframe\n",
    "- Check the DateTime for 2 cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-_dXNZFqd6rk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Aalborg</th>\n",
       "      <th>1980-03-01 00:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1008.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 00:20:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 00:50:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 01:20:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01 01:50:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Temp  Pressure  WindSpeed  WindDir\n",
       "City    DateTime                                               \n",
       "Aalborg 1980-03-01 00:00:00   5.0    1008.1       11.3    290.0\n",
       "        1980-03-01 00:20:00   4.0       NaN        9.2    270.0\n",
       "        1980-03-01 00:50:00   4.0       NaN        9.2    280.0\n",
       "        1980-03-01 01:20:00   4.0       NaN        9.2    280.0\n",
       "        1980-03-01 01:50:00   4.0       NaN        8.7    270.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temp         float64\n",
       "Pressure     float64\n",
       "WindSpeed    float64\n",
       "WindDir      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Temp', 'Pressure', 'WindSpeed', 'WindDir'], dtype='object')\n",
      "MultiIndex([( 'Aalborg', '1980-03-01 00:00:00'),\n",
      "            ( 'Aalborg', '1980-03-01 00:20:00'),\n",
      "            ( 'Aalborg', '1980-03-01 00:50:00'),\n",
      "            ( 'Aalborg', '1980-03-01 01:20:00'),\n",
      "            ( 'Aalborg', '1980-03-01 01:50:00'),\n",
      "            ( 'Aalborg', '1980-03-01 02:20:00'),\n",
      "            ( 'Aalborg', '1980-03-01 03:00:00'),\n",
      "            ( 'Aalborg', '1980-03-01 03:20:00'),\n",
      "            ( 'Aalborg', '1980-03-01 04:00:00'),\n",
      "            ( 'Aalborg', '1980-03-01 04:01:00'),\n",
      "            ...\n",
      "            ('Roskilde', '2018-03-01 20:50:00'),\n",
      "            ('Roskilde', '2018-03-01 21:00:00'),\n",
      "            ('Roskilde', '2018-03-01 21:20:00'),\n",
      "            ('Roskilde', '2018-03-01 21:50:00'),\n",
      "            ('Roskilde', '2018-03-01 22:00:00'),\n",
      "            ('Roskilde', '2018-03-01 22:20:00'),\n",
      "            ('Roskilde', '2018-03-01 22:50:00'),\n",
      "            ('Roskilde', '2018-03-01 23:00:00'),\n",
      "            ('Roskilde', '2018-03-01 23:20:00'),\n",
      "            ('Roskilde', '2018-03-01 23:50:00')],\n",
      "           names=['City', 'DateTime'], length=2918150)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that via pickle format that the dataframe is indexed on cities not on ordinal numbers like in csv formats. It is also evident that the other columns utilize the float datatype. As requested, we shall see the DateTime for two cities, Aalborg and Roskilde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1980-03-01 00:00:00', '1980-03-01 00:20:00',\n",
       "               '1980-03-01 00:50:00', '1980-03-01 01:20:00',\n",
       "               '1980-03-01 01:50:00', '1980-03-01 02:20:00',\n",
       "               '1980-03-01 03:00:00', '1980-03-01 03:20:00',\n",
       "               '1980-03-01 04:00:00', '1980-03-01 04:01:00',\n",
       "               ...\n",
       "               '2018-03-01 21:20:00', '2018-03-01 21:50:00',\n",
       "               '2018-03-01 22:00:00', '2018-03-01 22:20:00',\n",
       "               '2018-03-01 22:30:00', '2018-03-01 22:50:00',\n",
       "               '2018-03-01 23:00:00', '2018-03-01 23:04:00',\n",
       "               '2018-03-01 23:21:00', '2018-03-01 23:50:00'],\n",
       "              dtype='datetime64[ns]', name='DateTime', length=759897, freq=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.xs('Aalborg').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1980-03-01 10:50:00', '1980-03-01 12:50:00',\n",
       "               '1980-03-01 13:50:00', '1980-03-01 15:50:00',\n",
       "               '1980-03-01 16:50:00', '1980-03-02 04:50:00',\n",
       "               '1980-03-02 06:50:00', '1980-03-02 07:50:00',\n",
       "               '1980-03-02 09:50:00', '1980-03-02 10:50:00',\n",
       "               ...\n",
       "               '2018-03-01 20:50:00', '2018-03-01 21:00:00',\n",
       "               '2018-03-01 21:20:00', '2018-03-01 21:50:00',\n",
       "               '2018-03-01 22:00:00', '2018-03-01 22:20:00',\n",
       "               '2018-03-01 22:50:00', '2018-03-01 23:00:00',\n",
       "               '2018-03-01 23:20:00', '2018-03-01 23:50:00'],\n",
       "              dtype='datetime64[ns]', name='DateTime', length=569852, freq=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.xs('Roskilde').index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYcAldYgeOmq"
   },
   "source": [
    "## 2.2 - Interacting with a server to query a subset of some data bank\n",
    "\n",
    "We will now learn how to query a data bank to retrieve only the relevant proportion data for a task. We will be using the World Bank Data API to access World's renewable energy consumtpion data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz0G-PnEllEE"
   },
   "source": [
    "You first need to install the World Bank API. In a terminal, run the following command:\n",
    "\n",
    "``>> pip install wbdata``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "executionInfo": {
     "elapsed": 5409,
     "status": "ok",
     "timestamp": 1603899607656,
     "user": {
      "displayName": "Sephora Madjiheurem",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgieP2Hh5x42748iuuSEnAl8BYCWGSmOzJ-ypgSaQ=s64",
      "userId": "05055971560005673839"
     },
     "user_tz": 0
    },
    "id": "pKP6WMKA3YTH",
    "outputId": "b822a83a-4f1f-4ef3-88e6-ada5dc8e99a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wbdata in c:\\software\\anaconda\\lib\\site-packages (0.3.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: decorator>=4.0 in c:\\software\\anaconda\\lib\\site-packages (from wbdata) (5.0.6)\n",
      "Requirement already satisfied: requests>=2.0 in c:\\software\\anaconda\\lib\\site-packages (from wbdata) (2.25.1)\n",
      "Requirement already satisfied: appdirs<2.0,>=1.4 in c:\\software\\anaconda\\lib\\site-packages (from wbdata) (1.4.4)\n",
      "Requirement already satisfied: tabulate>=0.8.5 in c:\\software\\anaconda\\lib\\site-packages (from wbdata) (0.8.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\software\\anaconda\\lib\\site-packages (from requests>=2.0->wbdata) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\software\\anaconda\\lib\\site-packages (from requests>=2.0->wbdata) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\software\\anaconda\\lib\\site-packages (from requests>=2.0->wbdata) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\software\\anaconda\\lib\\site-packages (from requests>=2.0->wbdata) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "%pip install wbdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1603899609741,
     "user": {
      "displayName": "Sephora Madjiheurem",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgieP2Hh5x42748iuuSEnAl8BYCWGSmOzJ-ypgSaQ=s64",
      "userId": "05055971560005673839"
     },
     "user_tz": 0
    },
    "id": "TpOO5F8YkxyR"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import wbdata as wb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OJzq_rWmGa-"
   },
   "source": [
    "### - Query the World Bank\n",
    "\n",
    "* **_[TO DO]_**: Use the wbdata to retrieve renewable energy consumption data of all countries in 2015.\n",
    "\n",
    "Hint: [wbdata documentation](https://wbdata.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we shall analyse the provided data from World Bank. Here we can use get_source to obtain the whole list and find the energy consumption data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  id  name\n",
       "----  --------------------------------------------------------------------\n",
       "   1  Doing Business\n",
       "   2  World Development Indicators\n",
       "   3  Worldwide Governance Indicators\n",
       "   5  Subnational Malnutrition Database\n",
       "   6  International Debt Statistics\n",
       "  11  Africa Development Indicators\n",
       "  12  Education Statistics\n",
       "  13  Enterprise Surveys\n",
       "  14  Gender Statistics\n",
       "  15  Global Economic Monitor\n",
       "  16  Health Nutrition and Population Statistics\n",
       "  18  IDA Results Measurement System\n",
       "  19  Millennium Development Goals\n",
       "  20  Quarterly Public Sector Debt\n",
       "  22  Quarterly External Debt Statistics SDDS\n",
       "  23  Quarterly External Debt Statistics GDDS\n",
       "  24  Poverty and Equity\n",
       "  25  Jobs\n",
       "  27  Global Economic Prospects\n",
       "  28  Global Financial Inclusion\n",
       "  29  The Atlas of Social Protection: Indicators of Resilience and Equity\n",
       "  30  Exporter Dynamics Database â Indicators at Country-Year Level\n",
       "  31  Country Policy and Institutional Assessment\n",
       "  32  Global Financial Development\n",
       "  33  G20 Financial Inclusion Indicators\n",
       "  34  Global Partnership for Education\n",
       "  35  Sustainable Energy for All\n",
       "  36  Statistical Capacity Indicators\n",
       "  37  LAC Equity Lab\n",
       "  38  Subnational Poverty\n",
       "  39  Health Nutrition and Population Statistics by Wealth Quintile\n",
       "  40  Population estimates and projections\n",
       "  41  Country Partnership Strategy for India (FY2013 - 17)\n",
       "  43  Adjusted Net Savings\n",
       "  45  Indonesia Database for Policy and Economic Research\n",
       "  46  Sustainable Development Goals\n",
       "  50  Subnational Population\n",
       "  54  Joint External Debt Hub\n",
       "  57  WDI Database Archives\n",
       "  58  Universal Health Coverage\n",
       "  59  Wealth Accounts\n",
       "  60  Economic Fitness\n",
       "  61  PPPs Regulatory Quality\n",
       "  62  International Comparison Program (ICP) 2011\n",
       "  63  Human Capital Index\n",
       "  64  Worldwide Bureaucracy Indicators\n",
       "  65  Health Equity and Financial Protection Indicators\n",
       "  66  Logistics Performance Index\n",
       "  67  PEFA 2011\n",
       "  68  PEFA 2016\n",
       "  69  Global Financial Inclusion and Consumer Protection Survey\n",
       "  70  Economic Fitness 2\n",
       "  71  International Comparison Program (ICP) 2005\n",
       "  73  Global Financial Inclusion and Consumer Protection Survey (Internal)\n",
       "  75  Environment, Social and Governance (ESG) Data\n",
       "  76  Remittance Prices Worldwide (Sending Countries)\n",
       "  77  Remittance Prices Worldwide (Receiving Countries)\n",
       "  78  ICP 2017\n",
       "  79  PEFA_GRPFM\n",
       "  80  Gender Disaggregated Labor Database (GDLD)\n",
       "  81  International Debt Statistics: DSSI\n",
       "  82  Global Public Procurement\n",
       "  83  Statistical Performance Indicators (SPI)\n",
       "  84  Education Policy\n",
       "  85  PEFA_2021_SNG\n",
       "  86  Global Jobs Indicators Database (JOIN)\n",
       "  87  Country Climate and Development Report (CCDR)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb.get_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              name\n",
       "------------------------------  --------------------------------------------------------------------------\n",
       "1.1_ACCESS.ELECTRICITY.TOT      Access to electricity (% of total population)\n",
       "1.1_TOTAL.FINAL.ENERGY.CONSUM   Total final energy consumption (TFEC)\n",
       "1.2_ACCESS.ELECTRICITY.RURAL    Access to electricity (% of rural population)\n",
       "1.3_ACCESS.ELECTRICITY.URBAN    Access to electricity (% of urban population)\n",
       "2.1_ACCESS.CFT.TOT              Access to Clean Fuels and Technologies for cooking (% of total population)\n",
       "2.1_SHARE.TOTAL.RE.IN.TFEC      Renewable energy consumption(% in TFEC)\n",
       "3.1_RE.CONSUMPTION              Renewable energy consumption (TJ)\n",
       "4.1.1_TOTAL.ELECTRICITY.OUTPUT  Total electricity output (GWh)\n",
       "4.1.2_REN.ELECTRICITY.OUTPUT    Renewable energy electricity output (GWh)\n",
       "4.1_SHARE.RE.IN.ELECTRICITY     Renewable electricity (% in total electricity output)\n",
       "6.1_PRIMARY.ENERGY.INTENSITY    Energy intensity level of primary energy (MJ/$2005 PPP)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb.get_indicator(source=35)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired dataset lies in the WB dataset with id 3.1_RE.CONSUMPTION, so we can call this id for our use case. Furthermore, from documentation, we can set the time range to our target timeframe. In addition, we could also search for the indicator to avoid manual searching as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          name\n",
       "--------------------------  ------------------------------------------------------------------\n",
       "2.1_SHARE.TOTAL.RE.IN.TFEC  Renewable energy consumption(% in TFEC)\n",
       "3.1_RE.CONSUMPTION          Renewable energy consumption (TJ)\n",
       "EG.FEC.RNEW.ZS              Renewable energy consumption (% of total final energy consumption)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb.search_indicators(\"Renewable energy consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RXwfBzicmFO3"
   },
   "outputs": [],
   "source": [
    "### TODO\n",
    "# Selecting the time frame\n",
    "import datetime\n",
    "\n",
    "wb_energy=wb.get_dataframe({'3.1_RE.CONSUMPTION' : 'Renewable energy consumption (TJ)'}, data_date=(datetime.datetime(2015, 1, 1), datetime.datetime(2015, 12, 31)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Renewable energy consumption (TJ)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BES Islands</th>\n",
       "      <td>112.78860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nauru</th>\n",
       "      <td>0.32988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niue</th>\n",
       "      <td>16.63123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wallis and Futuna</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caucasian and Central Asia</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>6701.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Sahara</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen, Rep.</th>\n",
       "      <td>2433.20100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>301679.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>324422.60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Renewable energy consumption (TJ)\n",
       "country                                                      \n",
       "BES Islands                                         112.78860\n",
       "Nauru                                                 0.32988\n",
       "Niue                                                 16.63123\n",
       "Wallis and Futuna                                     0.00000\n",
       "Caucasian and Central Asia                                NaN\n",
       "...                                                       ...\n",
       "West Bank and Gaza                                 6701.55000\n",
       "Western Sahara                                        0.00000\n",
       "Yemen, Rep.                                        2433.20100\n",
       "Zambia                                           301679.80000\n",
       "Zimbabwe                                         324422.60000\n",
       "\n",
       "[259 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FB_UE-0nSeX"
   },
   "source": [
    "### - Undestanding the data\n",
    "\n",
    "* **_[TO DO]_**: Display different data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TLsp11GKn8Ai"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Renewable energy consumption (TJ)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BES Islands</th>\n",
       "      <td>112.78860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nauru</th>\n",
       "      <td>0.32988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niue</th>\n",
       "      <td>16.63123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wallis and Futuna</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caucasian and Central Asia</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caucasus and Central Asia</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastern Asia (including Japan)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastern Asia (not including Japan)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastern Europe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Renewable energy consumption (TJ)\n",
       "country                                                              \n",
       "BES Islands                                                 112.78860\n",
       "Nauru                                                         0.32988\n",
       "Niue                                                         16.63123\n",
       "Wallis and Futuna                                             0.00000\n",
       "Caucasian and Central Asia                                        NaN\n",
       "Caucasus and Central Asia                                         NaN\n",
       "Eastern Asia (including Japan)                                    NaN\n",
       "Eastern Asia (not including Japan)                                NaN\n",
       "Eastern Europe                                                    NaN\n",
       "Europe                                                            NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO\n",
    "wb_energy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "BES Islands                           112.78860\n",
       "Nauru                                   0.32988\n",
       "Niue                                   16.63123\n",
       "Wallis and Futuna                       0.00000\n",
       "Caucasian and Central Asia                  NaN\n",
       "Caucasus and Central Asia                   NaN\n",
       "Eastern Asia (including Japan)              NaN\n",
       "Eastern Asia (not including Japan)          NaN\n",
       "Eastern Europe                              NaN\n",
       "Europe                                      NaN\n",
       "Name: Renewable energy consumption (TJ), dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_energy['Renewable energy consumption (TJ)'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Renewable energy consumption (TJ)'], dtype='object')\n",
      "Index(['BES Islands', 'Nauru', 'Niue', 'Wallis and Futuna',\n",
      "       'Caucasian and Central Asia', 'Caucasus and Central Asia',\n",
      "       'Eastern Asia (including Japan)', 'Eastern Asia (not including Japan)',\n",
      "       'Eastern Europe', 'Europe',\n",
      "       ...\n",
      "       'Uzbekistan', 'Vanuatu', 'Venezuela, RB', 'Vietnam',\n",
      "       'Virgin Islands (U.S.)', 'West Bank and Gaza', 'Western Sahara',\n",
      "       'Yemen, Rep.', 'Zambia', 'Zimbabwe'],\n",
      "      dtype='object', name='country', length=259)\n"
     ]
    }
   ],
   "source": [
    "print(wb_energy.columns)\n",
    "print(wb_energy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Renewable energy consumption (TJ)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_energy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Renewable energy consumption (TJ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.330000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.645674e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.599198e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.336698e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.155545e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.283452e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.084482e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Renewable energy consumption (TJ)\n",
       "count                       2.330000e+02\n",
       "mean                        2.645674e+05\n",
       "std                         9.599198e+05\n",
       "min                         0.000000e+00\n",
       "25%                         8.336698e+02\n",
       "50%                         3.155545e+04\n",
       "75%                         1.283452e+05\n",
       "max                         9.084482e+06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Renewable energy consumption (TJ)    2402254.0\n",
       "Name: Indonesia, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_energy.xs('Indonesia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some quick analysis on the data, we see that the Renewable energy consumption (TJ) column is a float type value and also some insight regarding variance within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o52Lnoq5olC9"
   },
   "source": [
    "### - Exporting the data \n",
    "\n",
    "* **_[TO DO]_**: Save the retrieved renewable energy consumption data of all countries in 2015 in one .xlsx file\n",
    "* **_[TO DO]_**: Save the renewable energy consumption data from 2006 to 2016 for each European country in individual .csv files (one per country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-k6RXRXBpduC"
   },
   "source": [
    "### TODO Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to xlsx file for 2015 - All Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_energy_all=wb.get_dataframe({'3.1_RE.CONSUMPTION' : 'Renewable energy consumption (TJ)'}, \n",
    "                                   data_date=(datetime.datetime(2015, 1, 1), datetime.datetime(2015, 12, 31)))\n",
    "wb_energy_all.to_excel('renewable_energy_cosumption_2015.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to csv file for 2006 ~ 2016 - EU Countries (1 file each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the link provided by https://datahelpdesk.worldbank.org/knowledgebase/articles/898590-country-api-queries, we can utilize the country information obtained for selecting EU countries with the below fields:\n",
    "- 3 letter ISO 3166-1 alpha-3 code\n",
    "- 2 letter ISO 3166-1 alpha-2 code\n",
    "- Name\n",
    "- Region: ID, name and World Bank 2 letter code\n",
    "- Income Level: ID, name and World Bank 2 letter code\n",
    "- Lending Type: ID, name and World Bank 2 letter code\n",
    "- Capital City\n",
    "- Longitude\n",
    "- Latitude\n",
    "\n",
    "We are interested in the continent/region for EU, which is specified. Here, European countries have a 'region' field of ECS which stands for Europe and Central Asia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we will get the full country data via the WB API, and specify that we want it in JSON with all the data present (seen by the 1000 per page parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wbgapi as wbapi\n",
    "#from countrygroups import EUROPEAN_UNION\n",
    "\n",
    "#wbapi.economy.coder([\"USA\"])\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "wb_countries = requests.get(\"http://api.worldbank.org/v2/country?format=json&source=6&per_page=1000\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here countries are described in index 1, where we can see how each field is presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ABW',\n",
       " 'iso2Code': 'AW',\n",
       " 'name': 'Aruba',\n",
       " 'region': {'id': 'LCN',\n",
       "  'iso2code': 'ZJ',\n",
       "  'value': 'Latin America & Caribbean '},\n",
       " 'adminregion': {'id': '', 'iso2code': '', 'value': ''},\n",
       " 'incomeLevel': {'id': 'HIC', 'iso2code': 'XD', 'value': 'High income'},\n",
       " 'lendingType': {'id': 'LNX', 'iso2code': 'XX', 'value': 'Not classified'},\n",
       " 'capitalCity': 'Oranjestad',\n",
       " 'longitude': '-70.0167',\n",
       " 'latitude': '12.5167'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_countries[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wb_countries[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can select countries in Europe, obtaining the code and country name in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALB': 'Albania', 'AND': 'Andorra', 'ARM': 'Armenia', 'AUT': 'Austria', 'AZE': 'Azerbaijan', 'BEL': 'Belgium', 'BGR': 'Bulgaria', 'BIH': 'Bosnia and Herzegovina', 'BLR': 'Belarus', 'CHE': 'Switzerland', 'CHI': 'Channel Islands', 'CYP': 'Cyprus', 'CZE': 'Czech Republic', 'DEU': 'Germany', 'DNK': 'Denmark', 'ESP': 'Spain', 'EST': 'Estonia', 'FIN': 'Finland', 'FRA': 'France', 'FRO': 'Faroe Islands', 'GBR': 'United Kingdom', 'GEO': 'Georgia', 'GIB': 'Gibraltar', 'GRC': 'Greece', 'GRL': 'Greenland', 'HRV': 'Croatia', 'HUN': 'Hungary', 'IMN': 'Isle of Man', 'IRL': 'Ireland', 'ISL': 'Iceland', 'ITA': 'Italy', 'KAZ': 'Kazakhstan', 'KGZ': 'Kyrgyz Republic', 'LIE': 'Liechtenstein', 'LTU': 'Lithuania', 'LUX': 'Luxembourg', 'LVA': 'Latvia', 'MCO': 'Monaco', 'MDA': 'Moldova', 'MKD': 'North Macedonia', 'MNE': 'Montenegro', 'NLD': 'Netherlands', 'NOR': 'Norway', 'POL': 'Poland', 'PRT': 'Portugal', 'ROU': 'Romania', 'RUS': 'Russian Federation', 'SMR': 'San Marino', 'SRB': 'Serbia', 'SVK': 'Slovak Republic', 'SVN': 'Slovenia', 'SWE': 'Sweden', 'TJK': 'Tajikistan', 'TKM': 'Turkmenistan', 'TUR': 'Turkey', 'UKR': 'Ukraine', 'UZB': 'Uzbekistan', 'XKX': 'Kosovo'}\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "european_countries = {i[\"id\"]:i[\"name\"] for i in wb_countries[1] if i[\"region\"][\"id\"] == \"ECS\" }\n",
    "\n",
    "print(european_countries)\n",
    "print(len(european_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALB', 'AND', 'ARM', 'AUT', 'AZE', 'BEL', 'BGR', 'BIH', 'BLR', 'CHE', 'CHI', 'CYP', 'CZE', 'DEU', 'DNK', 'ESP', 'EST', 'FIN', 'FRA', 'FRO', 'GBR', 'GEO', 'GIB', 'GRC', 'GRL', 'HRV', 'HUN', 'IMN', 'IRL', 'ISL', 'ITA', 'KAZ', 'KGZ', 'LIE', 'LTU', 'LUX', 'LVA', 'MCO', 'MDA', 'MKD', 'MNE', 'NLD', 'NOR', 'POL', 'PRT', 'ROU', 'RUS', 'SMR', 'SRB', 'SVK', 'SVN', 'SWE', 'TJK', 'TKM', 'TUR', 'UKR', 'UZB', 'XKX']\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "european_countries_ids = list(european_countries.keys())\n",
    "print(european_countries_ids)\n",
    "print(len(european_countries_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can proceed to convert all European country data into individual files by looping through our dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current saving %s ALB\n",
      "Current saving %s AND\n",
      "Current saving %s ARM\n",
      "Current saving %s AUT\n",
      "Current saving %s AZE\n",
      "Current saving %s BEL\n",
      "Current saving %s BGR\n",
      "Current saving %s BIH\n",
      "Current saving %s BLR\n",
      "Current saving %s CHE\n",
      "Current saving %s CHI\n",
      "Current saving %s CYP\n",
      "Current saving %s CZE\n",
      "Current saving %s DEU\n",
      "Current saving %s DNK\n",
      "Current saving %s ESP\n",
      "Current saving %s EST\n",
      "Current saving %s FIN\n",
      "Current saving %s FRA\n",
      "Current saving %s FRO\n",
      "Current saving %s GBR\n",
      "Current saving %s GEO\n",
      "Current saving %s GIB\n",
      "Current saving %s GRC\n",
      "Current saving %s GRL\n",
      "Current saving %s HRV\n",
      "Current saving %s HUN\n",
      "Current saving %s IMN\n",
      "Current saving %s IRL\n",
      "Current saving %s ISL\n",
      "Current saving %s ITA\n",
      "Current saving %s KAZ\n",
      "Current saving %s KGZ\n",
      "Current saving %s LIE\n",
      "Current saving %s LTU\n",
      "Current saving %s LUX\n",
      "Current saving %s LVA\n",
      "Current saving %s MCO\n",
      "Current saving %s MDA\n",
      "Current saving %s MKD\n",
      "Current saving %s MNE\n",
      "Current saving %s NLD\n",
      "Current saving %s NOR\n",
      "Current saving %s POL\n",
      "Current saving %s PRT\n",
      "Current saving %s ROU\n",
      "Current saving %s RUS\n",
      "Current saving %s SMR\n",
      "Current saving %s SRB\n",
      "Current saving %s SVK\n",
      "Current saving %s SVN\n",
      "Current saving %s SWE\n",
      "Current saving %s TJK\n",
      "Current saving %s TKM\n",
      "Current saving %s TUR\n",
      "Current saving %s UKR\n",
      "Current saving %s UZB\n",
      "Current saving %s XKX\n"
     ]
    }
   ],
   "source": [
    "for eu_id in european_countries_ids:\n",
    "    eu_country_energy = wb.get_dataframe({'3.1_RE.CONSUMPTION' : 'Renewable energy consumption (TJ)'}, \n",
    "                                   data_date=(datetime.datetime(2006, 1, 1), datetime.datetime(2016, 12, 31)), \n",
    "                                   country=eu_id)\n",
    "    eu_country_energy.to_csv(european_countries[eu_id] + '_2006_2016.csv')\n",
    "    print(\"Current saving %s\",eu_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LAB1.ipynb",
   "provenance": [
    {
     "file_id": "1HXjyjuj11ovY200lbVrY4ksJrv4eEphn",
     "timestamp": 1603281631972
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
